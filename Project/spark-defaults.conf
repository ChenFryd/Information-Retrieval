# Configure Spark on YARN
spark.master=yarn

# Dynamic allocation on YARN
spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.minExecutors=1
spark.executor.instances=10000
spark.dynamicAllocation.maxExecutors=10000
spark.shuffle.service.enabled=true
spark.scheduler.minRegisteredResourcesRatio=0.0

# This undoes setting hive.execution.engine to tez in hive-site.xml
# It is not used by Spark
spark.hadoop.hive.execution.engine=mr

spark.rpc.message.maxSize=512

# Adding namespace to extract app_name and app_id for spark metrics
spark.metrics.namespace=app_name:${spark.app.name}.app_id:${spark.app.id}

# On clusters without Kerberos integration, use unmanaged AM to speed-up Spark
# Context initialization and free-up 1 YARN container per-AM.
# On clusters integrated with Kerberos, YARN unmanaged AM setting will be
# disabled though.
spark.yarn.unmanagedAM.enabled=true

# Enable adaptive query execution, which re-optimizes the query plan
# in the middle of query execution, based on accurate runtime statistics.
spark.sql.adaptive.enabled=true
# Reorder joins when cost-based optimization enabled to improve performance.
spark.sql.cbo.joinReorder.enabled=true

spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2

# Enables vectorized parquet reader for complex types
spark.sql.parquet.enableNestedColumnVectorizedReader=true

spark.eventLog.enabled=true
spark.eventLog.dir=gs://dataproc-temp-us-central1-403887540253-mj4hjaja/8430a129-f47e-4841-829e-5c7bfe44c087/spark-job-history
spark.history.fs.logDirectory=gs://dataproc-temp-us-central1-403887540253-mj4hjaja/8430a129-f47e-4841-829e-5c7bfe44c087/spark-job-history

spark.yarn.historyServer.address=cluster-502f-m:18080

spark.dataproc.metrics.listener.metrics.collector.hostname=cluster-502f-m

# Enable using Hive as the metastore for Spark
spark.sql.catalogImplementation=hive
spark.checkpoint.compress=true

spark.submit.deployMode=client
spark.yarn.jars=local:/usr/lib/spark/jars/*


# User-supplied properties.
#Sun Mar 10 07:51:59 UTC 2024
spark.yarn.am.memory=640m
spark.executor.memory=2893m
spark.driver.memory=2048m
spark.driver.maxResultSize=1024m
spark.dataproc.sql.optimizer.join.fusion.enabled=true
spark.executor.cores=1
spark.ui.port=0
spark.executorEnv.OPENBLAS_NUM_THREADS=1
spark.dataproc.listeners=com.google.cloud.spark.performance.DataprocMetricsListener
spark.sql.optimizer.runtime.bloomFilter.join.pattern.enabled=true
spark.dataproc.advanced.infer.filter.enabled=true
spark.dataproc.sql.optimizer.leftsemijoin.conversion.enabled=true
spark.dataproc.sql.local.rank.pushdown.enabled=true
spark.dataproc.sql.optimizer.scalar.subquery.fusion.enabled=true
spark.dataproc.enhanced.optimizer.enabled=true
spark.scheduler.mode=FAIR
spark.dataproc.sql.joinConditionReorder.enabled=true
spark.sql.cbo.enabled=true
spark.dataproc.sql.parquet.enableFooterCache=true
spark.executor.instances=2

spark.sql.autoBroadcastJoinThreshold=21m
